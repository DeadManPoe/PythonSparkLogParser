{"Event":"SparkListenerLogStart","Spark Version":"1.6.0"}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"10.22.1.3","Port":57090},"Maximum Memory":535953408,"Timestamp":1479835133909}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/pico/prod/compilers/jre/1.8.0_73/none","Java Version":"1.8.0_73 (Oracle Corporation)","Scala Version":"version 2.10.5"},"Spark Properties":{"spark.driver.host":"10.22.1.3","spark.eventLog.enabled":"true","spark.driver.port":"56944","spark.jars":"file:/pico/home/userexternal/dardagna/Spark1.6/spark-1.6.0-bin-hadoop2.4/lib/spark-examples-1.6.0-hadoop2.4.0.jar","spark.app.name":"Spark Pi","spark.scheduler.mode":"FIFO","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://node003:7077","spark.eventLog.dir":"/pico/home/userexternal/dardagna/spark-logs","spark.externalBlockStore.folderName":"spark-7255caf5-ff50-4557-a05a-9560f0308630","spark.app.id":"app-20161122181853-0000"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.8","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.8","user.home":"/pico/home/userexternal/dardagna","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"64","sun.boot.library.path":"/pico/prod/compilers/jre/1.8.0_73/none/lib/amd64","user.dir":"/pico/home/userexternal/dardagna","java.library.path":"/cineca/prod/compilers/python/2.7.9/none/lib:/cineca/prod/compilers/jre/1.8.0_73/none/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"25.73-b02","java.endorsed.dirs":"/pico/prod/compilers/jre/1.8.0_73/none/lib/endorsed","java.runtime.version":"1.8.0_73-b02","java.vm.info":"mixed mode","java.ext.dirs":"/pico/prod/compilers/jre/1.8.0_73/none/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"Java(TM) SE Runtime Environment","file.separator":"/","java.class.version":"52.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/pico/prod/compilers/jre/1.8.0_73/none/lib/resources.jar:/pico/prod/compilers/jre/1.8.0_73/none/lib/rt.jar:/pico/prod/compilers/jre/1.8.0_73/none/lib/sunrsasign.jar:/pico/prod/compilers/jre/1.8.0_73/none/lib/jsse.jar:/pico/prod/compilers/jre/1.8.0_73/none/lib/jce.jar:/pico/prod/compilers/jre/1.8.0_73/none/lib/charsets.jar:/pico/prod/compilers/jre/1.8.0_73/none/lib/jfr.jar:/pico/prod/compilers/jre/1.8.0_73/none/classes","file.encoding":"UTF-8","user.timezone":"Europe/Rome","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"2.6.32-431.el6.x86_64","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"dardagna","java.vm.name":"Java HotSpot(TM) 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://node003:7077 --conf spark.eventLog.enabled=true --conf spark.eventLog.dir=/pico/home/userexternal/dardagna/spark-logs --class org.apache.spark.examples.SparkPi /pico/home/userexternal/dardagna/Spark1.6/spark-1.6.0-bin-hadoop2.4/lib/spark-examples-1.6.0-hadoop2.4.0.jar","java.home":"/pico/prod/compilers/jre/1.8.0_73/none","java.version":"1.8.0_73","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/pico/home/userexternal/dardagna/Spark1.6/spark-1.6.0-bin-hadoop2.4/lib/datanucleus-api-jdo-3.2.6.jar":"System Classpath","/pico/home/userexternal/dardagna/Spark1.6/spark-1.6.0-bin-hadoop2.4/conf/":"System Classpath","/pico/home/userexternal/dardagna/Spark1.6/spark-1.6.0-bin-hadoop2.4/lib/datanucleus-rdbms-3.2.9.jar":"System Classpath","/pico/home/userexternal/dardagna/Spark1.6/spark-1.6.0-bin-hadoop2.4/lib/spark-assembly-1.6.0-hadoop2.4.0.jar":"System Classpath","/pico/home/userexternal/dardagna/Spark1.6/spark-1.6.0-bin-hadoop2.4/lib/datanucleus-core-3.2.10.jar":"System Classpath","http://10.22.1.3:53193/jars/spark-examples-1.6.0-hadoop2.4.0.jar":"Added By User"}}
{"Event":"SparkListenerApplicationStart","App Name":"Spark Pi","App ID":"app-20161122181853-0000","Timestamp":1479835130718,"User":"dardagna"}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1479835134559,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"reduce at SparkPi.scala:36","Number of Tasks":2,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"map\"}","Callsite":"map at SparkPi.scala:32","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"0\",\"name\":\"parallelize\"}","Callsite":"parallelize at SparkPi.scala:32","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\norg.apache.spark.examples.SparkPi$.main(SparkPi.scala:36)\norg.apache.spark.examples.SparkPi.main(SparkPi.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"2\",\"name\":\"reduce\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"reduce at SparkPi.scala:36","Number of Tasks":2,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"map\"}","Callsite":"map at SparkPi.scala:32","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"0\",\"name\":\"parallelize\"}","Callsite":"parallelize at SparkPi.scala:32","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\norg.apache.spark.examples.SparkPi$.main(SparkPi.scala:36)\norg.apache.spark.examples.SparkPi.main(SparkPi.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"2\",\"name\":\"reduce\"}"}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1479835140972,"Executor ID":"0","Executor Info":{"Host":"node003.pico.cineca.it","Total Cores":20,"Log Urls":{"stdout":"http://10.22.1.3:8081/logPage/?appId=app-20161122181853-0000&executorId=0&logType=stdout","stderr":"http://10.22.1.3:8081/logPage/?appId=app-20161122181853-0000&executorId=0&logType=stderr"}}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1479835140975,"Executor ID":"0","Host":"node003.pico.cineca.it","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1479835140992,"Executor ID":"0","Host":"node003.pico.cineca.it","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"node003.pico.cineca.it","Port":53143},"Maximum Memory":536346624,"Timestamp":1479835141016}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1479835140975,"Executor ID":"0","Host":"node003.pico.cineca.it","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1479835143547,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"node003.pico.cineca.it","Executor Deserialize Time":2376,"Executor Run Time":117,"Result Size":1044,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":1,"Attempt":0,"Launch Time":1479835140992,"Executor ID":"0","Host":"node003.pico.cineca.it","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1479835143548,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"node003.pico.cineca.it","Executor Deserialize Time":2376,"Executor Run Time":118,"Result Size":1044,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"reduce at SparkPi.scala:36","Number of Tasks":2,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"map\"}","Callsite":"map at SparkPi.scala:32","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"0\",\"name\":\"parallelize\"}","Callsite":"parallelize at SparkPi.scala:32","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\norg.apache.spark.examples.SparkPi$.main(SparkPi.scala:36)\norg.apache.spark.examples.SparkPi.main(SparkPi.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1479835134695,"Completion Time":1479835143551,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1479835143553,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1479835143557}
